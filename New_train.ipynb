{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df9fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "CODE_DIR = '/home/joshua/Projects/diffae'\n",
    "os.chdir(f'{CODE_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "177a5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_msssim import ms_ssim\n",
    "import torch\n",
    "import lpips\n",
    "\n",
    "l1_criterion = torch.nn.L1Loss(reduction='mean')\n",
    "l2_criterion = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "\n",
    "def rec_loss(attr_images, generated_images, a):\n",
    "    ms_ssim_loss = 1 - ms_ssim(attr_images, generated_images, data_range=1, size_average=True)\n",
    "    l1_loss_value = l1_criterion(attr_images, generated_images)\n",
    "    return a * ms_ssim_loss + (1 - a) * l1_loss_value\n",
    "\n",
    "\n",
    "def id_loss(encoded_input_image, encoded_generated_image):\n",
    "    return l1_criterion(encoded_input_image, encoded_generated_image)\n",
    "\n",
    "\n",
    "def landmark_loss(input_attr_lnd, output_lnd):\n",
    "    loss = l2_criterion(input_attr_lnd, output_lnd)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def l2_loss(attr_images, generated_images):\n",
    "    loss = l2_criterion(attr_images, generated_images)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7361ccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: 160.69 M\n",
      "Loading ResNet ArcFace\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/joshua/anaconda3/envs/proj0/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "from templates import *\n",
    "from templates_cls import *\n",
    "from experiment_classifier import ClsModel\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/joshua/Projects/diffae/disentanglement/')\n",
    "\n",
    "from Configs import Global_Config\n",
    "from Configs.training_config import config, GENERATOR_IMAGE_SIZE\n",
    "from Training.trainer import Trainer\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from Models.Encoders.Landmark_Encoder import Landmark_Encoder\n",
    "from Models.Encoders.ID_Encoder import ID_Encoder\n",
    "from Models.Encoders.Inception import Inception\n",
    "from Models.LatentMapper import LatentMapper\n",
    "from Utils.data_utils import get_w_image, Image_W_Dataset, cycle_images_to_create_diff_order\n",
    "import time\n",
    "import torch.utils.data\n",
    "from tqdm import tqdm\n",
    "from Losses import id_loss\n",
    "\n",
    "device = 'cuda:0'\n",
    "conf = ffhq256_autoenc()\n",
    "# print(conf.name)\n",
    "model = LitModel(conf)\n",
    "state = torch.load(f'checkpoints/{conf.name}/last.ckpt', map_location='cpu')\n",
    "model.load_state_dict(state['state_dict'], strict=False)\n",
    "model.ema_model.to(device)\n",
    "# model.ema_model.requires_grad_(True)\n",
    "model.ema_model.eval()\n",
    "model.eval()\n",
    "# torch.set_grad_enabled(True)\n",
    "\n",
    "BASE_PATH = '/home/joshua/Projects/diffae/disentanglement/'\n",
    "MOBILE_FACE_NET_WEIGHTS_PATH = BASE_PATH + 'CNN-project-weights/mobilefacenet_model_best.pth.tar'\n",
    "GENERATOR_WEIGHTS_PATH = BASE_PATH + 'CNN-project-weights/550000.pt'\n",
    "E_ID_LOSS_PATH = BASE_PATH + 'CNN-project-weights/model_ir_se50.pth'\n",
    "IMAGE_DATA_DIR = BASE_PATH + 'Dataset/small_image/'\n",
    "W_DATA_DIR = BASE_PATH + 'Dataset/small_w/'\n",
    "MODELS_DIR = BASE_PATH + 'Models/'\n",
    "\n",
    "id_encoder = id_loss.IDLoss(E_ID_LOSS_PATH)\n",
    "# attr_encoder = torch.load(MODELS_DIR + 'attr_encoder_HPMNYYOTTIXN_1616315604.9508004_0.pt')\n",
    "attr_encoder = torch.load('/home/joshua/Projects/diffae/checkpoints/attr/attr_ffhq15000_att_mlp.pt')\n",
    "attr_encoder = Inception(attr_encoder)\n",
    "# discriminator = Discriminator()\n",
    "mlp = LatentMapper()\n",
    "landmark_encoder = Landmark_Encoder.Encoder_Landmarks(MOBILE_FACE_NET_WEIGHTS_PATH)\n",
    "# mlp = torch.load(MODELS_DIR + 'maper_HPMNYYOTTIXN_1616315604.542634_0.pt')\n",
    "mlp = torch.load('/home/joshua/Projects/diffae/checkpoints/MLP/mlp_ffhq15000_att_mlp.pt')\n",
    "\n",
    "id_encoder = id_encoder.to(Global_Config.device)\n",
    "attr_encoder = attr_encoder.to(Global_Config.device)\n",
    "# discriminator = discriminator.to(Global_Config.device)\n",
    "mlp = mlp.to(Global_Config.device)\n",
    "landmark_encoder = landmark_encoder.to(Global_Config.device)\n",
    "\n",
    "id_encoder = id_encoder.eval()\n",
    "lpips_loss = lpips.LPIPS(net='alex').to(Global_Config.device).eval()\n",
    "landmark_encoder = landmark_encoder.eval()\n",
    "attr_encoder = attr_encoder.train()\n",
    "\n",
    "mlp = mlp.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb5da196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "L2 = nn.MSELoss()\n",
    "\n",
    "config = {\n",
    "    'beta1' : 0.5,\n",
    "    'beta2' : 0.999,\n",
    "    'lrD' : 0.0004,\n",
    "    'lrMLP' : 0.00003,\n",
    "    'lrAttr' : 0.0001,\n",
    "    'non_adverserial_lr': 6e-5,\n",
    "    'IdDiffersAttrTrainRatio' : 3, # 1/3\n",
    "    'batchSize' : 8,\n",
    "    'R1Param' : 10,\n",
    "    'lambdaID' : 1,\n",
    "    'lambdaLND' : 1,\n",
    "    'lambdaREC' : 1,\n",
    "    'lambdaL2' : 1,\n",
    "    'lambdaVGG' : 1,\n",
    "    'a': 0.84\n",
    "}\n",
    "\n",
    "optimizerMLP = torch.optim.Adam(mlp.parameters(), lr=config['lrMLP'], betas=(config['beta1'], config['beta2']))\n",
    "optimizer_non_adv_M = torch.optim.Adam(list(mlp.parameters()) + list(attr_encoder.parameters()),\n",
    "                                       lr=config['non_adverserial_lr'], betas=(config['beta1'], config['beta2']))\n",
    "# image_data = ImageDataset('00000', image_size=conf.img_size, exts=['jpg', 'JPG', 'png'], do_augment=False)\n",
    "# print(len(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5432a152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img': tensor([[[-0.9686, -1.0000, -0.9843,  ..., -0.9843, -0.9922, -0.9843],\n",
      "         [-0.9765, -1.0000, -0.9922,  ..., -0.9922, -1.0000, -0.9922],\n",
      "         [-0.9686, -0.9922, -1.0000,  ..., -0.9922, -1.0000, -1.0000],\n",
      "         ...,\n",
      "         [-0.8275, -0.8196, -0.8118,  ...,  0.0196,  0.0275,  0.0353],\n",
      "         [-0.8745, -0.8588, -0.8510,  ...,  0.0667,  0.0824,  0.0745],\n",
      "         [-0.8745, -0.8667, -0.8588,  ...,  0.0275,  0.0588,  0.0510]],\n",
      "\n",
      "        [[ 0.0275, -0.0275,  0.0118,  ..., -0.0667, -0.0980, -0.0902],\n",
      "         [ 0.0196, -0.0118,  0.0039,  ..., -0.0980, -0.1137, -0.0980],\n",
      "         [ 0.0275,  0.0039, -0.0039,  ..., -0.1137, -0.1216, -0.1216],\n",
      "         ...,\n",
      "         [ 0.2078,  0.2157,  0.2235,  ...,  0.2157,  0.2157,  0.2235],\n",
      "         [ 0.1529,  0.1686,  0.1765,  ...,  0.2549,  0.2471,  0.2392],\n",
      "         [ 0.1529,  0.1608,  0.1686,  ...,  0.2157,  0.2235,  0.2157]],\n",
      "\n",
      "        [[ 0.1451,  0.0902,  0.1451,  ...,  0.2078,  0.1843,  0.1922],\n",
      "         [ 0.1373,  0.1059,  0.1373,  ...,  0.1843,  0.1686,  0.1843],\n",
      "         [ 0.1608,  0.1373,  0.1294,  ...,  0.1843,  0.1765,  0.1765],\n",
      "         ...,\n",
      "         [ 0.3255,  0.3333,  0.3412,  ...,  0.2549,  0.2471,  0.2549],\n",
      "         [ 0.2941,  0.3098,  0.3176,  ...,  0.2863,  0.2863,  0.2784],\n",
      "         [ 0.2941,  0.3020,  0.3098,  ...,  0.2471,  0.2627,  0.2549]]]), 'index': 0}\n",
      "{'img': tensor([[[-0.9843, -0.9922, -0.9843,  ..., -0.9843, -1.0000, -0.9686],\n",
      "         [-0.9922, -1.0000, -0.9922,  ..., -0.9922, -1.0000, -0.9765],\n",
      "         [-1.0000, -1.0000, -0.9922,  ..., -1.0000, -0.9922, -0.9686],\n",
      "         ...,\n",
      "         [ 0.0353,  0.0275,  0.0196,  ..., -0.8118, -0.8196, -0.8275],\n",
      "         [ 0.0745,  0.0824,  0.0667,  ..., -0.8510, -0.8588, -0.8745],\n",
      "         [ 0.0510,  0.0588,  0.0275,  ..., -0.8588, -0.8667, -0.8745]],\n",
      "\n",
      "        [[-0.0902, -0.0980, -0.0667,  ...,  0.0118, -0.0275,  0.0275],\n",
      "         [-0.0980, -0.1137, -0.0980,  ...,  0.0039, -0.0118,  0.0196],\n",
      "         [-0.1216, -0.1216, -0.1137,  ..., -0.0039,  0.0039,  0.0275],\n",
      "         ...,\n",
      "         [ 0.2235,  0.2157,  0.2157,  ...,  0.2235,  0.2157,  0.2078],\n",
      "         [ 0.2392,  0.2471,  0.2549,  ...,  0.1765,  0.1686,  0.1529],\n",
      "         [ 0.2157,  0.2235,  0.2157,  ...,  0.1686,  0.1608,  0.1529]],\n",
      "\n",
      "        [[ 0.1922,  0.1843,  0.2078,  ...,  0.1451,  0.0902,  0.1451],\n",
      "         [ 0.1843,  0.1686,  0.1843,  ...,  0.1373,  0.1059,  0.1373],\n",
      "         [ 0.1765,  0.1765,  0.1843,  ...,  0.1294,  0.1373,  0.1608],\n",
      "         ...,\n",
      "         [ 0.2549,  0.2471,  0.2549,  ...,  0.3412,  0.3333,  0.3255],\n",
      "         [ 0.2784,  0.2863,  0.2863,  ...,  0.3176,  0.3098,  0.2941],\n",
      "         [ 0.2549,  0.2627,  0.2471,  ...,  0.3098,  0.3020,  0.2941]]]), 'index': 1}\n",
      "{'img': tensor([[[-0.9843, -0.9922, -0.9843,  ..., -0.9373, -0.9373, -0.9373],\n",
      "         [-0.9843, -0.9843, -0.9843,  ..., -0.9373, -0.9373, -0.9373],\n",
      "         [-0.9843, -0.9843, -0.9843,  ..., -0.9294, -0.9294, -0.9294],\n",
      "         ...,\n",
      "         [-0.1451, -0.1294, -0.1451,  ...,  0.6314,  0.5765,  0.4902],\n",
      "         [-0.1529, -0.1529, -0.1451,  ...,  0.5843,  0.6078,  0.6549],\n",
      "         [-0.1451, -0.1529, -0.1608,  ...,  0.5608,  0.5922,  0.6627]],\n",
      "\n",
      "        [[-0.9843, -0.9922, -0.9843,  ..., -0.9765, -0.9765, -0.9765],\n",
      "         [-0.9843, -0.9843, -0.9843,  ..., -0.9765, -0.9765, -0.9765],\n",
      "         [-0.9843, -0.9843, -0.9843,  ..., -0.9686, -0.9765, -0.9765],\n",
      "         ...,\n",
      "         [-0.8118, -0.7961, -0.7961,  ...,  0.0196, -0.0353, -0.1216],\n",
      "         [-0.8039, -0.8039, -0.7961,  ..., -0.0275, -0.0039,  0.0431],\n",
      "         [-0.7961, -0.8039, -0.8118,  ..., -0.0510, -0.0196,  0.0510]],\n",
      "\n",
      "        [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -0.9922, -0.9765, -0.9765],\n",
      "         ...,\n",
      "         [-0.9686, -0.9529, -0.9373,  ..., -0.3412, -0.3961, -0.4824],\n",
      "         [-0.9451, -0.9451, -0.9373,  ..., -0.4039, -0.3804, -0.3333],\n",
      "         [-0.9373, -0.9451, -0.9529,  ..., -0.4275, -0.3961, -0.3255]]]), 'index': 2}\n"
     ]
    }
   ],
   "source": [
    "conf = ffhq256_autoenc()\n",
    "image_data = conf.make_dataset()\n",
    "# batch = data[10]['img'][None]\n",
    "for idx, data in enumerate(image_data):\n",
    "    if idx == 1:\n",
    "        break\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33c1db4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 9.78 GiB total capacity; 7.59 GiB already allocated; 13.19 MiB free; 7.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             xT_true \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode_stochastic(id_images, semantic_vec_true, T\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     32\u001b[0m         semantic_vec \u001b[38;5;241m=\u001b[39m mlp(encoded_vec)\n\u001b[0;32m---> 34\u001b[0m         generated_img \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxT_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msemantic_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#         id_encoder.zero_grad()\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#         landmark_encoder.zero_grad()\u001b[39;00m\n\u001b[1;32m     38\u001b[0m         \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#         rec_loss_val = config['lambdaREC'] * rec_loss(attr_images, generated_img, config['a'])\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#         total_loss += rec_loss_val\u001b[39;00m\n\u001b[1;32m     47\u001b[0m         l2_loss_val \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambdaL2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m l2_loss(attr_images, generated_img)\n",
      "File \u001b[0;32m~/Projects/diffae/experiment.py:137\u001b[0m, in \u001b[0;36mLitModel.render\u001b[0;34m(self, noise, cond, T)\u001b[0m\n\u001b[1;32m    134\u001b[0m     sampler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconf\u001b[38;5;241m.\u001b[39m_make_diffusion_conf(T)\u001b[38;5;241m.\u001b[39mmake_sampler()\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cond \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     pred_img \u001b[38;5;241m=\u001b[39m \u001b[43mrender_condition\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mema_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                                \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     pred_img \u001b[38;5;241m=\u001b[39m render_uncondition(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconf,\n\u001b[1;32m    144\u001b[0m                                   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema_model,\n\u001b[1;32m    145\u001b[0m                                   noise,\n\u001b[1;32m    146\u001b[0m                                   sampler\u001b[38;5;241m=\u001b[39msampler,\n\u001b[1;32m    147\u001b[0m                                   latent_sampler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/diffae/renderer.py:56\u001b[0m, in \u001b[0;36mrender_condition\u001b[0;34m(conf, model, x_T, sampler, x_start, cond)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cond \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m         cond \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(x_start)\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_T\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcond\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "File \u001b[0;32m~/Projects/diffae/diffusion/base.py:208\u001b[0m, in \u001b[0;36mGaussianDiffusionBeatGans.sample\u001b[0;34m(self, model, shape, noise, cond, x_start, clip_denoised, model_kwargs, progress)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_sample_loop(model,\n\u001b[1;32m    202\u001b[0m                               shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m    203\u001b[0m                               noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[1;32m    204\u001b[0m                               clip_denoised\u001b[38;5;241m=\u001b[39mclip_denoised,\n\u001b[1;32m    205\u001b[0m                               model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs,\n\u001b[1;32m    206\u001b[0m                               progress\u001b[38;5;241m=\u001b[39mprogress)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconf\u001b[38;5;241m.\u001b[39mgen_type \u001b[38;5;241m==\u001b[39m GenerativeType\u001b[38;5;241m.\u001b[39mddim:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddim_sample_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "File \u001b[0;32m~/Projects/diffae/diffusion/base.py:735\u001b[0m, in \u001b[0;36mGaussianDiffusionBeatGans.ddim_sample_loop\u001b[0;34m(self, model, shape, noise, clip_denoised, denoised_fn, cond_fn, model_kwargs, device, progress, eta)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;124;03mGenerate samples from the model using DDIM.\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \n\u001b[1;32m    732\u001b[0m \u001b[38;5;124;03mSame usage as p_sample_loop().\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    734\u001b[0m final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 735\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mddim_sample_loop_progressive(\n\u001b[1;32m    736\u001b[0m         model,\n\u001b[1;32m    737\u001b[0m         shape,\n\u001b[1;32m    738\u001b[0m         noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[1;32m    739\u001b[0m         clip_denoised\u001b[38;5;241m=\u001b[39mclip_denoised,\n\u001b[1;32m    740\u001b[0m         denoised_fn\u001b[38;5;241m=\u001b[39mdenoised_fn,\n\u001b[1;32m    741\u001b[0m         cond_fn\u001b[38;5;241m=\u001b[39mcond_fn,\n\u001b[1;32m    742\u001b[0m         model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs,\n\u001b[1;32m    743\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    744\u001b[0m         progress\u001b[38;5;241m=\u001b[39mprogress,\n\u001b[1;32m    745\u001b[0m         eta\u001b[38;5;241m=\u001b[39meta,\n\u001b[1;32m    746\u001b[0m ):\n\u001b[1;32m    747\u001b[0m     final \u001b[38;5;241m=\u001b[39m sample\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/diffae/diffusion/base.py:795\u001b[0m, in \u001b[0;36mGaussianDiffusionBeatGans.ddim_sample_loop_progressive\u001b[0;34m(self, model, shape, noise, clip_denoised, denoised_fn, cond_fn, model_kwargs, device, progress, eta)\u001b[0m\n\u001b[1;32m    793\u001b[0m             t \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mtensor([i] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(img), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m#             with th.no_grad():\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m             out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddim_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m                \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m                \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcond_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m                \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m             out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m t\n\u001b[1;32m    806\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m out\n",
      "File \u001b[0;32m~/Projects/diffae/diffusion/base.py:600\u001b[0m, in \u001b[0;36mGaussianDiffusionBeatGans.ddim_sample\u001b[0;34m(self, model, x, t, clip_denoised, denoised_fn, cond_fn, model_kwargs, eta)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mddim_sample\u001b[39m(\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    586\u001b[0m     model: Model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    593\u001b[0m     eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    594\u001b[0m ):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m    Sample x_{t-1} from the model using DDIM.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    Same usage as p_sample().\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 600\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cond_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    609\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcondition_score(cond_fn,\n\u001b[1;32m    610\u001b[0m                                    out,\n\u001b[1;32m    611\u001b[0m                                    x,\n\u001b[1;32m    612\u001b[0m                                    t,\n\u001b[1;32m    613\u001b[0m                                    model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs)\n",
      "File \u001b[0;32m~/Projects/diffae/diffusion/diffusion.py:96\u001b[0m, in \u001b[0;36mSpacedDiffusionBeatGans.p_mean_variance\u001b[0;34m(self, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_mean_variance\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: Model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# pylint: disable=signature-differs\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/diffae/diffusion/base.py:307\u001b[0m, in \u001b[0;36mGaussianDiffusionBeatGans.p_mean_variance\u001b[0;34m(self, model, x, t, clip_denoised, denoised_fn, model_kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m t\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (B, )\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconf\u001b[38;5;241m.\u001b[39mfp16):\n\u001b[0;32m--> 307\u001b[0m     model_forward \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scale_timesteps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m model_output \u001b[38;5;241m=\u001b[39m model_forward\u001b[38;5;241m.\u001b[39mpred\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_var_type \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    313\u001b[0m         ModelVarType\u001b[38;5;241m.\u001b[39mfixed_large, ModelVarType\u001b[38;5;241m.\u001b[39mfixed_small\n\u001b[1;32m    314\u001b[0m ]:\n",
      "File \u001b[0;32m~/Projects/diffae/diffusion/diffusion.py:153\u001b[0m, in \u001b[0;36m_WrappedModel.forward\u001b[0;34m(self, x, t, t_cond, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t_cond \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# support t_cond\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     t_cond \u001b[38;5;241m=\u001b[39m do(t_cond)\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_cond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/proj0/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/diffae/model/unet_autoenc.py:241\u001b[0m, in \u001b[0;36mBeatGANsAutoencModel.forward\u001b[0;34m(self, x, t, y, x_start, cond, style, noise, t_cond, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m             lateral \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    239\u001b[0m             \u001b[38;5;66;03m# print(i, j, lateral)\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m         h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_blocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43memb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_time_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_cond_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mlateral\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlateral\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m         k \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    247\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(h)\n",
      "File \u001b[0;32m~/anaconda3/envs/proj0/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/diffae/model/blocks.py:39\u001b[0m, in \u001b[0;36mTimestepEmbedSequential.forward\u001b[0;34m(self, x, emb, cond, lateral)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, TimestepBlock):\n\u001b[0;32m---> 39\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlateral\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlateral\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/proj0/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/diffae/model/blocks.py:193\u001b[0m, in \u001b[0;36mResBlock.forward\u001b[0;34m(self, x, emb, cond, lateral)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, emb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cond\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, lateral\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    Apply the block to a Tensor, conditioned on a timestep embedding.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m        lateral: lateral connection from the encoder\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlateral\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/diffae/model/nn.py:137\u001b[0m, in \u001b[0;36mtorch_checkpoint\u001b[0;34m(func, args, flag, preserve_rng_state)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    135\u001b[0m         func, \u001b[38;5;241m*\u001b[39margs, preserve_rng_state\u001b[38;5;241m=\u001b[39mpreserve_rng_state)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/diffae/model/blocks.py:247\u001b[0m, in \u001b[0;36mResBlock._forward\u001b[0;34m(self, x, emb, cond, lateral)\u001b[0m\n\u001b[1;32m    244\u001b[0m         cond_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# this is the new refactored code\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mapply_conditions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43memb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mup_down_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_connection(x) \u001b[38;5;241m+\u001b[39m h\n",
      "File \u001b[0;32m~/Projects/diffae/model/blocks.py:321\u001b[0m, in \u001b[0;36mapply_conditions\u001b[0;34m(h, emb, cond, layers, scale_bias, in_channels, up_down_layer)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# spilt the post layer to be able to scale up or down before conv\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# post layers will contain only the conv\u001b[39;00m\n\u001b[1;32m    319\u001b[0m mid_layers, post_layers \u001b[38;5;241m=\u001b[39m post_layers[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], post_layers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m--> 321\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mpre_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# scale and shift for each condition\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (scale, shift) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(scale_shifts):\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;66;03m# if scale is None, it indicates that the condition is not provided\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/proj0/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/diffae/model/nn.py:25\u001b[0m, in \u001b[0;36mGroupNorm32.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/proj0/lib/python3.9/site-packages/torch/nn/modules/normalization.py:268\u001b[0m, in \u001b[0;36mGroupNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/proj0/lib/python3.9/site-packages/torch/nn/functional.py:2499\u001b[0m, in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(group_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias,), \u001b[38;5;28minput\u001b[39m, num_groups, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps)\n\u001b[1;32m   2498\u001b[0m _verify_batch_size([\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_groups, num_groups] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m2\u001b[39m:]))\n\u001b[0;32m-> 2499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 9.78 GiB total capacity; 7.59 GiB already allocated; 13.19 MiB free; 7.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "# def toggle_grad(model, requires_grad):\n",
    "#     for p in model.parameters():\n",
    "#         p.requires_grad_(requires_grad)\n",
    "\n",
    "\n",
    "# toggle_grad(model, True)\n",
    "\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for idx, data in enumerate(image_data):\n",
    "        batch = data['img'][None]\n",
    "        torch.cuda.empty_cache()\n",
    "        gen_img = batch.detach().clone()\n",
    "        id_images = batch.cuda()\n",
    "        generated_img = Variable(gen_img, requires_grad = True)\n",
    "        generated_img = generated_img.cuda()\n",
    "#         print(generated_img)\n",
    "        attr_batch = batch*0.5+0.5\n",
    "        attr_images = attr_batch.cuda()\n",
    "#         xT_true = xT_list[idx][None]\n",
    "#         xT_true = xT_true.cuda()\n",
    "        \n",
    "        total_loss = torch.tensor(0, dtype=torch.float, device=Global_Config.device)\n",
    "       \n",
    "        id_vec = id_encoder.extract_feats(id_images)\n",
    "        attr_vec = torch.squeeze(attr_encoder(attr_images))[None]\n",
    "        encoded_vec = torch.cat((id_vec,attr_vec), dim=1)\n",
    "        with torch.no_grad():\n",
    "            semantic_vec_true = model.encode(id_images)\n",
    "            xT_true = model.encode_stochastic(id_images, semantic_vec_true, T=20)\n",
    "        semantic_vec = mlp(encoded_vec)\n",
    "\n",
    "        generated_img = model.render(xT_true, semantic_vec, T=20)\n",
    "\n",
    "#         id_encoder.zero_grad()\n",
    "#         landmark_encoder.zero_grad()\n",
    "        \n",
    "        ## -1 to 1\n",
    "#         id_loss_val = config['lambdaID'] * id_encoder(generated_img*2-1, id_images)\n",
    "#         total_loss += id_loss_val\n",
    "        \n",
    "        ## 0 to 1\n",
    "#         rec_loss_val = config['lambdaREC'] * rec_loss(attr_images, generated_img, config['a'])\n",
    "#         total_loss += rec_loss_val\n",
    "        \n",
    "        l2_loss_val = config['lambdaL2'] * l2_loss(attr_images, generated_img)\n",
    "        total_loss += l2_loss_val\n",
    "        \n",
    "        ## -1 to 1\n",
    "#         vgg_loss_val = torch.mean(config['lambdaVGG'] * lpips_loss(generated_img*2-1, id_images))\n",
    "#         total_loss += vgg_loss_val\n",
    "        \n",
    "        optimizer_non_adv_M.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer_non_adv_M.step()\n",
    "        \n",
    "        if idx%20==0:\n",
    "            print('ID:', idx, 'l2_loss_val:',total_loss.item())\n",
    "#         print('id_loss_val:',id_loss_val.item(),'rec_loss_val:',rec_loss_val.item(),'l2_loss_val:',l2_loss_val.item(),'vgg_loss_val:',vgg_loss_val.item())\n",
    "#         print(f\"\\n loss:\", total_loss.item(), 'idx:', idx)\n",
    "\n",
    "#     MLP_losses.append(g_error)\n",
    "#     D_losses.append((error_real + error_fake) /2)\n",
    "\n",
    "#     if idx % 5 == 0:\n",
    "#         with torch.no_grad():\n",
    "#             plot_w_image(mlp(test_vec)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d80b9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.9922, -0.9922, -0.9922,  ..., -0.0902, -0.2471, -0.2314],\n",
       "          [-0.9922, -0.9922, -0.9922,  ..., -0.2157, -0.2392, -0.3333],\n",
       "          [-0.9922, -0.9922, -0.9922,  ..., -0.2314, -0.2078, -0.3098],\n",
       "          ...,\n",
       "          [ 0.5765,  0.4745,  0.4588,  ...,  0.7098,  0.7020,  0.6941],\n",
       "          [ 0.6157,  0.6392,  0.5843,  ...,  0.7176,  0.7098,  0.7020],\n",
       "          [ 0.6314,  0.5843,  0.4667,  ...,  0.7412,  0.7176,  0.7098]],\n",
       "\n",
       "         [[-0.9922, -0.9922, -0.9922,  ..., -0.2549, -0.3961, -0.4118],\n",
       "          [-0.9922, -0.9922, -0.9922,  ..., -0.4510, -0.3725, -0.4902],\n",
       "          [-0.9922, -0.9922, -0.9922,  ..., -0.4902, -0.3490, -0.4745],\n",
       "          ...,\n",
       "          [ 0.5451,  0.4118,  0.3961,  ..., -0.4745, -0.4902, -0.4980],\n",
       "          [ 0.6157,  0.6314,  0.5765,  ..., -0.4667, -0.4588, -0.4824],\n",
       "          [ 0.6078,  0.5608,  0.4588,  ..., -0.4588, -0.4431, -0.4667]],\n",
       "\n",
       "         [[-1.0000, -1.0000, -0.9922,  ..., -0.2471, -0.3882, -0.3725],\n",
       "          [-0.9922, -0.9922, -0.9922,  ..., -0.4588, -0.3647, -0.4745],\n",
       "          [-0.9922, -0.9922, -0.9922,  ..., -0.4980, -0.3333, -0.4588],\n",
       "          ...,\n",
       "          [ 0.4824,  0.3490,  0.3020,  ..., -0.7961, -0.8118, -0.8196],\n",
       "          [ 0.5294,  0.5373,  0.4667,  ..., -0.7882, -0.7882, -0.8039],\n",
       "          [ 0.5608,  0.5059,  0.4039,  ..., -0.7804, -0.7804, -0.7961]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5716bc72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
