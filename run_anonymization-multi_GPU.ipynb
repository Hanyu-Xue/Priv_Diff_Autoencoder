{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0258379c",
   "metadata": {},
   "source": [
    "# 1. 文件夹操作, 保证文件存在"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c19b0",
   "metadata": {},
   "source": [
    "## 1.1 读取json文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# 用法示例\n",
    "file_path = '/home/joshua/Projects/dataset/Diffusion_data/farl_brute_cosine_nn_map_celeba.json'  # 替换为你的 JSON 文件路径\n",
    "json_data = read_json_file(file_path)\n",
    "print('待操作文件数:',len(json_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee98f72",
   "metadata": {},
   "source": [
    "## 1.2 文件夹操作, 将原始celebAHQ的文件转换为以下文件列表的形式并存在新的文件夹中:\n",
    "\n",
    "```\n",
    "|-real dataset\n",
    "    |-0\n",
    "        |-0.jpg\n",
    "    |-1\n",
    "        |-1.jpg\n",
    "    |-2\n",
    "        |-2.jpg\n",
    "    |-3\n",
    "        |-3.jpg\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original path to load\n",
    "ori_real_folder = \"/home/joshua/Projects/dataset/CelebAMask-HQ/data\"\n",
    "\n",
    "# folder path to save\n",
    "new_real_folder = '/home/joshua/Projects/dataset/Diffusion_data/real_dataset'\n",
    "os.makedirs(real_dataset_folder, exist_ok=True)\n",
    "\n",
    "for real_file, _ in json_data.items():\n",
    "#     print(real_file, fake_file)\n",
    "    source_path = os.path.join(ori_real_folder, real_file)\n",
    "    real_fold = real_file.replace('.jpg', '')\n",
    "    REAL_path = os.path.join(new_real_folder, real_fold)\n",
    "    os.makedirs(REAL_path, exist_ok=True)\n",
    "    \n",
    "    destination_path = os.path.join(REAL_path, real_file)\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7c3c07",
   "metadata": {},
   "source": [
    "# 2. 匿名化操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab59cc",
   "metadata": {},
   "source": [
    "## 2.1 读取json文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# 用法示例\n",
    "file_path = '/home/joshua/Projects/dataset/Diffusion_data/farl_brute_cosine_nn_map_celeba.json'  # 替换为你的 JSON 文件路径\n",
    "json_data = read_json_file(file_path)\n",
    "print('待操作文件数:',len(json_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba23356",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data['3.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87881157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对字典按键进行排序，并构建新的有序字典\n",
    "sorted_data = {}\n",
    "for i in range(len(json_data)):\n",
    "    new_key = f\"{i}.jpg\"\n",
    "    sorted_data[new_key] = json_data[new_key]\n",
    "    \n",
    "# sorted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68a171d",
   "metadata": {},
   "source": [
    "## 2.2 准备数据集对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0113003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_folder_path = '/home/joshua/Projects/dataset/Diffusion_data/real_dataset'\n",
    "fake_folder_path = '/home/joshua/Projects/dataset/Diffusion_data/fake_dataset'\n",
    "\n",
    "real_path_list = []\n",
    "fake_path_list = []\n",
    "\n",
    "random_choose = False\n",
    "total_items = 10  # 选取张数\n",
    "\n",
    "if random_choose:\n",
    "    json_file = json_data\n",
    "else:\n",
    "    json_file = sorted_data\n",
    "\n",
    "count = 0\n",
    "\n",
    "for real_file, fake_file in json_file.items():\n",
    "    if count < total_items:\n",
    "        real_fold = real_file.replace('.jpg', '')\n",
    "        real_path = os.path.join(real_folder_path, real_fold)\n",
    "        real_path_list.append(real_path)\n",
    "        split_strings = fake_file.split('/') # 拆开字符串\n",
    "        fake_fold = split_strings[-1] # 获取最后一个子字符串\n",
    "        fake_path = os.path.join(fake_folder_path, fake_fold)\n",
    "        fake_path_list.append(fake_path)\n",
    "#         print(real_path)\n",
    "        count = count+1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ccdbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(real_path_list)\n",
    "print(fake_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ff7b3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from templates import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(fake_path_list)):\n",
    "    real_data = ImageDataset(real_path_list[i], image_size=256, exts=['jpg', 'JPG', 'png'], do_augment=False)\n",
    "    real_image = real_data[0]['img'][None]\n",
    "    Real_image = (real_image + 1) / 2\n",
    "    fake_data = ImageDataset(fake_path_list[i], image_size=256, exts=['jpg', 'JPG', 'png'], do_augment=False)\n",
    "    fake_image = fake_data[0]['img'][None]\n",
    "    Fake_image = (fake_image + 1) / 2\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(Real_image[0].permute(1, 2, 0).cpu())\n",
    "    ax[1].imshow(Fake_image[0].permute(1, 2, 0).cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a7e40",
   "metadata": {},
   "source": [
    "## 2.3 读取并优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "from templates import *\n",
    "from templates_cls import *\n",
    "from experiment_classifier import ClsModel\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/joshua/Projects/diffae/disentanglement/')\n",
    "from Losses import id_loss\n",
    "\n",
    "device =\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#----------------Load diffusion model----------------------#\n",
    "Diff_conf = ffhq256_autoenc()\n",
    "# print(Diff_conf.name)\n",
    "Diff_model = LitModel(Diff_conf)\n",
    "Diff_state = torch.load(f'checkpoints/{Diff_conf.name}/last.ckpt', map_location='cpu')\n",
    "Diff_model.load_state_dict(Diff_state['state_dict'], strict=False)\n",
    "Diff_model.ema_model.to(device)\n",
    "Diff_model.ema_model.eval()\n",
    "\n",
    "#----------------Load FaRL and Arcface model----------------------#\n",
    "FaRL_model, preprocess = clip.load(\"ViT-B/16\", device=\"cpu\")\n",
    "FaRL_model = FaRL_model.to(device)\n",
    "FaRL_state=torch.load(\"FaRL/checkpoints/FaRL-Base-Patch16-LAIONFace20M-ep64.pth\") # you can download from https://github.com/FacePerceiver/FaRL#pre-trained-backbones\n",
    "FaRL_model.load_state_dict(FaRL_state[\"state_dict\"],strict=False)\n",
    "\n",
    "BASE_PATH = '/home/joshua/Projects/diffae/disentanglement/'\n",
    "E_ID_LOSS_PATH = BASE_PATH + 'CNN-project-weights/model_ir_se50.pth'\n",
    "Arc_model = id_loss.IDLoss(E_ID_LOSS_PATH)\n",
    "Arc_model = Arc_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b69ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def extract_left_digits(number, num_digits):\n",
    "    number_str = str(number)\n",
    "    result = number_str[:num_digits]\n",
    "    return result\n",
    "\n",
    "def cosine_distance(x_A, x_R, m):\n",
    "    # Calculate cosine similarity\n",
    "    cos_sim = torch.dot(x_A, x_R) / (torch.norm(x_A) * torch.norm(x_R))\n",
    "    # Calculate absolute difference with m\n",
    "    abs_diff = torch.abs(cos_sim - m)\n",
    "    return abs_diff\n",
    "\n",
    "def l1_distance(x_A, x_R):\n",
    "    # Calculate L1 distance\n",
    "    diff = x_A - x_R\n",
    "    dist = torch.norm(diff, p=1)\n",
    "    return dist\n",
    "\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "FaRL_transform0 = transforms.Compose([\n",
    "    transforms.Resize(size=224, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.Normalize(mean=(0.48145466, 0.4578275, 0.40821073), \n",
    "                         std=(0.26862954, 0.26130258, 0.27577711))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b2f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anon_folder_path = '/home/joshua/Projects/dataset/Diffusion_data/anon_dataset'\n",
    "os.makedirs(anon_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ab77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "lr_id = 0.01               # image id learning rate\n",
    "lr_attribute = 0.0003       # image attribute learning rate\n",
    "\n",
    "T = 10                     # process step number for diffusion model\n",
    "iter_number = 100           # iteration number for optimization\n",
    "stop_threshold = 1.5*10000*lr_attribute  # stop optimization iteration when loss lower than stop_threshold\n",
    "\n",
    "# set m in range [0,1], 0 indicates the max distance in ID Space, 1 or 0.9 indicate the min distance in ID Space.\n",
    "m = 0\n",
    "        \n",
    "for i in range(len(fake_path_list)):\n",
    "    # 0.0 Data to process\n",
    "    real_data = ImageDataset(real_path_list[i], image_size=256, exts=['jpg', 'JPG', 'png'], do_augment=False)\n",
    "    fake_data = ImageDataset(fake_path_list[i], image_size=256, exts=['jpg', 'JPG', 'png'], do_augment=False)\n",
    "    \n",
    "    if not fake_data or not real_data:\n",
    "        print('check the data path, fake_data or real_data do not exists!!')\n",
    "        break\n",
    "    else:\n",
    "        anon_save_path = os.path.join(anon_folder_path, str(i))\n",
    "        os.makedirs(anon_save_path, exist_ok=True)\n",
    "        \n",
    "        real_batch = real_data[0]['img'][None]\n",
    "        real_image = real_batch.cuda()    # (range:[-1,1]; size:[1,3,256,256])\n",
    "\n",
    "        fake_batch = fake_data[0]['img'][None]\n",
    "        fake_image = fake_batch.cuda()    # (range:[-1,1]; size:[1,3,256,256])\n",
    "\n",
    "        # Real Data\n",
    "        Real_image = (real_image + 1) / 2 # (range:[0,1]; size:[1,3,256,256])\n",
    "\n",
    "        # Collect arcface gradient information here\n",
    "        with torch.no_grad():\n",
    "            Real_ID_Feat = Arc_model.extract_feats(Real_image)\n",
    "\n",
    "        # Collect FaRL gradient information here\n",
    "        with torch.no_grad():\n",
    "            FaRL_Patch_Real_image = FaRL_model.visual.conv1(FaRL_transform0(Real_image))  # torch.Size([1, 768, 14, 14])\n",
    "\n",
    "        FaRL_Patch_Real_image_Flatten = FaRL_Patch_Real_image.view(1, -1)\n",
    "\n",
    "        # 0.1 Fake Data\n",
    "        with torch.no_grad():\n",
    "            # no gradient info in this step, cause these tensor do not used to calculate while optimization\n",
    "            semantic_vec = Diff_model.encode(fake_image)\n",
    "            xT = Diff_model.encode_stochastic(fake_image, semantic_vec, T=T)\n",
    "            Fake_image = Diff_model.render(xT, semantic_vec, T=T)  # (range:[0,1]; size:[1,3,256,256])\n",
    "            \n",
    "            semantic_vec_real = Diff_model.encode(real_image)\n",
    "            xT_real = Diff_model.encode_stochastic(real_image, semantic_vec_real, T=T)\n",
    "            \n",
    "        # 0.2 Variable used to optimization. `require gradient` set to true\n",
    "        semantic_optimization = Variable(semantic_vec, requires_grad = True)  \n",
    "        \n",
    "        # loop\n",
    "        print('Optimization start for:', fake_path_list[i])\n",
    "        for j in range(iter_number):\n",
    "            torch.cuda.empty_cache()\n",
    "            # 0.3 Collect generator gradient information here\n",
    "            Fake_image_optimization = Diff_model.render(xT_real, semantic_optimization, T=T)\n",
    "\n",
    "            Fake_ID_Feat = Arc_model.extract_feats(Fake_image_optimization)\n",
    "            ArcFace_Loss = cosine_distance(Real_ID_Feat[0], Fake_ID_Feat[0], m)\n",
    "\n",
    "            FaRL_Patch_Fake_image = FaRL_model.visual.conv1(FaRL_transform0(Fake_image_optimization))  # torch.Size([1, 768, 14, 14])\n",
    "            FaRL_Patch_Fake_image_Flatten = FaRL_Patch_Fake_image.view(1, -1)\n",
    "            FaRL_Patch_Loss = l1_distance(FaRL_Patch_Real_image_Flatten, FaRL_Patch_Fake_image_Flatten)\n",
    "            \n",
    "            if ArcFace_Loss.item()<0.1:\n",
    "                Total_loss = lr_attribute * FaRL_Patch_Loss + 0.1\n",
    "            else:\n",
    "                Total_loss = ArcFace_Loss + lr_attribute * FaRL_Patch_Loss\n",
    "            \n",
    "            # 0.6 set all nets gradient to zero before backpropagation\n",
    "            Diff_model.zero_grad()\n",
    "            Arc_model.zero_grad()\n",
    "            FaRL_model.zero_grad()\n",
    "\n",
    "            # 0.7 partial derivative at ID\n",
    "            semantic_optimization.retain_grad() # gradient reatin on semantic_optimization\n",
    "            Total_loss.backward(retain_graph=True)   # partial derivative at ID\n",
    "\n",
    "            # update semantic_optimization with ID loss\n",
    "            semantic_optimization = semantic_optimization - lr_id*torch.sign(semantic_optimization.grad)\n",
    "\n",
    "#             # loop\n",
    "#             # 0.8 partial derivative at Attributes\n",
    "#             Diff_model.zero_grad()\n",
    "#             Arc_model.zero_grad()\n",
    "#             FaRL_model.zero_grad()\n",
    "\n",
    "#             semantic_optimization.retain_grad() # gradient reatin on semantic_optimization\n",
    "#             FaRL_Patch_Loss.backward()   # partial derivative at Attributes\n",
    "\n",
    "#             # update semantic_optimization with Attribute loss\n",
    "#             semantic_optimization = semantic_optimization - lr_attribute*torch.sign(semantic_optimization.grad)\n",
    "            \n",
    "            \n",
    "            print(\"Total_loss:\", extract_left_digits(Total_loss.item(),6), \n",
    "                  \"ID Loss:\", extract_left_digits(ArcFace_Loss.item(),6), \n",
    "                  \"ATTR Loss:\", extract_left_digits(FaRL_Patch_Loss.item()*lr_attribute,6))\n",
    "            if Total_loss.item()<stop_threshold:\n",
    "                print('循环中断在:',iter_number)\n",
    "                break\n",
    "        \n",
    "        print('Optimization end for:', fake_path_list[i])\n",
    "        with torch.no_grad():\n",
    "            Fake_image_optimization = Diff_model.render(xT_real, semantic_optimization, T=T)\n",
    "\n",
    "        Anonymization_Image = Fake_image_optimization[0].permute(1, 2, 0).cpu()\n",
    "\n",
    "        # 将图像转换为PIL Image对象\n",
    "        anon_image = Image.fromarray((Anonymization_Image * 255).numpy().astype('uint8'))\n",
    "\n",
    "        # 保存图像为文件\n",
    "        output_name = str(i)+'.jpg'\n",
    "        output_file = os.path.join(anon_save_path, output_name)  # 输出图像文件路径\n",
    "        anon_image.save(output_file)\n",
    "        print(\"图像保存完成:\",output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f5b001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
